{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill UDR_APM_Indicators.csv\n",
    "\n",
    "This notebook is used to fill system based created file with all indicators with an own custom mapping which basically comes\n",
    "from a custom CSV file. The CSV file needs to be the following structure. \n",
    "\n",
    "| Column | name | Data type | Description |\n",
    "| ------ | ---- | --------- | -------- |\n",
    "| 1 | PAI_Beschreibung | String | PAI Equipment Description |\n",
    "| 2 | PAI_Equipment | Int64 | PAI Equipment |\n",
    "| 3 | PAI_Datenpunkte | String | PAI Indicator |\n",
    "| 4 | PAI_Indikatorgruppe | String | PAI Indicator Group |\n",
    "| 5 | Separator | String | Empty Column for better reading |\n",
    "| 6 | Beschreibung | String | Target Equipment Description APM |\n",
    "| 7 | Equipment | Int64 | Target Equipment APM |\n",
    "| 8 | Merkmal | String | Target Characteristic APM |\n",
    "| 9 | Position | String | Target Position APM |\n",
    "\n",
    "See CSV file `CUSTOM_MAPPING_SAMPLE.csv` as reference.\n",
    "\n",
    "The CSV file is accessed by column index. So it can also be named different, but the column position must be the same.\n",
    "Once the tool has filled the customer input values in the UDR report we save this into a new file named:\n",
    "`UDR_APM_Indicators_filled.csv`. Please check carefully if all data was filled correct and then replace the system\n",
    "generated file with this file. (Delete the file `UDR_APM_Indicators.csv` and rename the the file `UDR_APM_Indicators_filled.csv` to `UDR_APM_Indicators.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "#import sys\n",
    "import csv\n",
    "\n",
    "# get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"current work directory: {current_dir}\")\n",
    "\n",
    "# if the current working directory not ends with \"notebooks\", change it to the parent directory\n",
    "if not current_dir.endswith(\"notebooks\"):\n",
    "\n",
    "    workspace_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    os.chdir(workspace_root)\n",
    "\n",
    "    # # Add the workspace root to the Python path\n",
    "    # sys.path.insert(0, workspace_root)\n",
    "\n",
    "    print(f\"changed root work directory to: {workspace_root}\")\n",
    "\n",
    "from modules.util.config import get_config_by_id  # noqa: E402\n",
    "\n",
    "CONFIG_ID = 'CUSTOM_TEST'\n",
    "TRANSFORM = get_config_by_id(CONFIG_ID)[\"transform\"][\"indicator\"]\n",
    "EXTRACTION_DIR = TRANSFORM[\"directory\"]\n",
    "REPORTS_DIR = f\"{EXTRACTION_DIR}/reports\"\n",
    "INDICATOR_CATEGORY = TRANSFORM[\"defaults\"][\"apm_default_indicator_category\"]\n",
    "\n",
    "# files\n",
    "udr_file = f\"{REPORTS_DIR}/UDR_APM_Indicators.csv\"\n",
    "custom_mapping_path = os.path.join(workspace_root, \"custom\", \"CUSTUM_MAPPING.csv\")\n",
    "output_path = f\"{REPORTS_DIR}/UDR_APM_Indicators_filled.csv\"\n",
    "\n",
    "def load_csv(file_path, delimiter=\",\"):\n",
    "    with open(file_path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.DictReader(file, delimiter=delimiter)\n",
    "        return list(reader)\n",
    "\n",
    "\n",
    "def save_csv(file_path, data, fieldnames, delimiter=\",\"):\n",
    "    with open(file_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames, delimiter=delimiter)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "# Main Logic\n",
    "udr_data = load_csv(udr_file, delimiter=\",\")\n",
    "custom_mapping_data = load_csv(custom_mapping_path, delimiter=\";\")\n",
    "\n",
    "try:\n",
    "    # Mapping durchführen\n",
    "    for udr_row in udr_data:\n",
    "        found_mapping = False\n",
    "        # Use a separate counter for the row index\n",
    "        row_index = udr_data.index(udr_row) + 1\n",
    "        print(f\"Processing row {row_index} of {len(udr_data)}\")\n",
    "        for custom_row in custom_mapping_data:\n",
    "            if (\n",
    "                udr_row[\"Internal ID\"] == custom_row[\"PAI_Equipment\"]  # Internal ID -> PAI_Equipment\n",
    "                and udr_row[\"Indicator Group\"] == custom_row[\"PAI_Indikatorgruppe\"]  # Indicator Group -> PAI_Indikatorgruppe\n",
    "                and udr_row[\"Indicator\"] == custom_row[\"PAI_Datenpunkte\"]  # Indicator -> PAI_Datenpunkte\n",
    "            ):\n",
    "                # Werte aus CUSTOM_MAPPING.csv übernehmen\n",
    "                udr_row[\"Input: APM Indicator Position\"] = custom_row[\"Position\"]  # Input: APM Indicator Position -> Position\n",
    "                udr_row[\"Input: ERP Characteristic\"] = custom_row[\"Merkmal\"]  # Input: ERP Characteristic -> Merkmal\n",
    "                udr_row[\"Input: APM Indicator Category\"] = INDICATOR_CATEGORY  # Input: APM Indicator Category\n",
    "                print(\n",
    "                    f\"Mapping found for: {udr_row[\"Internal ID\"]} - \"\n",
    "                    f\"{udr_row[\"Indicator Group\"]} with position \"\n",
    "                    f\"{custom_row[\"Position\"]}\"\n",
    "                )\n",
    "                found_mapping = True\n",
    "                break\n",
    "        if not found_mapping:\n",
    "            print(\n",
    "                f\"No mapping found for: {udr_row['Internal ID']} - {udr_row['Indicator']}\"\n",
    "            )\n",
    "\n",
    "    # print the number of rows in udr_data\n",
    "    print(f\"Lines of data in udr_data: {len(udr_data)}\")\n",
    "\n",
    "    # Delete all lines with empty \"Input: APM Indicator Position\"\n",
    "    udr_data = [\n",
    "        row for row in udr_data if row[\"Input: APM Indicator Position\"].strip()\n",
    "    ]\n",
    "    # Delete all lines with empty \"Input: ERP Characteristic\"\n",
    "    udr_data = [row for row in udr_data if row[\"Input: ERP Characteristic\"].strip()]\n",
    "    # Delete all lines with empty \"Input: APM Indicator Category\"\n",
    "    udr_data = [\n",
    "        row for row in udr_data if row[\"Input: APM Indicator Category\"].strip()\n",
    "    ]\n",
    "\n",
    "    print(f\"Lines of data in udr_data after cleaning: {len(udr_data)}\")\n",
    "\n",
    "    # save the cleaned data to a new CSV file\n",
    "    save_csv(output_path, udr_data, fieldnames=udr_data[0].keys(), delimiter=\",\")\n",
    "    print(f\"Saved cleaned data to {output_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Column missing in CSV: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unknown error occured: {e}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
